// arc/services/ai/public/mojom/ai_service.mojom-interop.h is auto generated by mojom_bindings_generator.py, do not edit

#pragma once

#include <cstdint>
#include <optional>
#include <string>
#include <variant>
#include <vector>

namespace arc::interop {

struct UserData {
  uint16_t id;
  uint64_t pointer;
};


enum class AIServiceType {embedding = 0,inference = 1,
};

enum class AIServiceError {illegalState = 0,invalidParameter = 1,notImplemented = 2,notInitialized = 3,alreadyInitialized = 4,invalidLibraryPath = 5,libraryNotFound = 6,libraryMissingRequiredSymbols = 7,cannotDownloadModel = 8,otherError = 9,
};

enum class AIEmbeddingSupportedModel {gteSmall = 0,gteBase = 1,gteLarge = 2,alibabaGteBase = 3,
};

enum class AIEmbeddingMethod {onnxRuntime = 0,coreML = 1,mLX = 2,remote = 3,
};

enum class AIInferenceModelType {phi2 = 0,phi3_5 = 1,mistral7B = 2,codeLlama13b = 3,llama_3_2 = 4,gemma2b = 5,qwen205b = 6,openelm270m = 7,
};

struct AIEmbeddingConfiguration {
  AIEmbeddingConfiguration() = default;
  ~AIEmbeddingConfiguration() = default;
  AIEmbeddingMethod method;
  std::optional<AIEmbeddingSupportedModel> model;
};

struct AIServiceConfiguration {
  AIServiceConfiguration() = default;
  ~AIServiceConfiguration() = default;
  AIServiceType type;
  std::string displayName;
  std::string libraryPath;
  std::string libraryVersion;
  int8_t maxRetries;
  double timeoutSeconds;
};

struct AIStreamedInferenceConfiguration {
  AIStreamedInferenceConfiguration() = default;
  ~AIStreamedInferenceConfiguration() = default;
  int32_t maxTokens;
  int16_t streamAfterEveryNTokens;
  AIInferenceModelType modelType;
};

struct Embeddings {
  Embeddings() = default;
  ~Embeddings() = default;
  std::vector<std::vector<float>> embeddings;
};



using AIErrorOrServiceType = std::variant<
  AIServiceType,
  AIServiceError
>;

using AIErrorOrEmbeddings = std::variant<
  Embeddings,
  AIServiceError
>;

class AIService;

class AIStreamedInferenceListener;

class AIService {
 public:
  AIService() = default;
  virtual ~AIService() = default;
  using InitializeCallback = void (*)(std::optional<AIServiceError>, UserData);
  virtual void Initialize(const AIServiceConfiguration& config, InitializeCallback closure, UserData userData) = 0;
  using TypeCallback = void (*)(const AIErrorOrServiceType&, UserData);
  virtual void Type(TypeCallback closure, UserData userData) = 0;
  using WaitForDebuggerToAttachCallback = void (*)(UserData);
  virtual void WaitForDebuggerToAttach(uint16_t seconds, WaitForDebuggerToAttachCallback closure, UserData userData) = 0;
  using CrashCallback = void (*)(UserData);
  virtual void Crash(CrashCallback closure, UserData userData) = 0;
  using UpdateFeatureFlagsCallback = void (*)(bool, UserData);
  virtual void UpdateFeatureFlags(const std::string& feature_flags_as_json, UpdateFeatureFlagsCallback closure, UserData userData) = 0;
  using GetEmbeddingsForCallback = void (*)(const AIErrorOrEmbeddings&, UserData);
  virtual void GetEmbeddingsFor(const std::vector<std::string>& inputs, const AIEmbeddingConfiguration& config, GetEmbeddingsForCallback closure, UserData userData) = 0;
  using LoadInferenceModelCallback = void (*)(std::optional<AIServiceError>, UserData);
  virtual void LoadInferenceModel(AIInferenceModelType model, LoadInferenceModelCallback closure, UserData userData) = 0;
  using GetStreamedInferenceForCallback = void (*)(std::optional<AIServiceError>, UserData);
  virtual void GetStreamedInferenceFor(const std::string& prompt, const AIStreamedInferenceConfiguration& config, AIStreamedInferenceListener* listener, GetStreamedInferenceForCallback closure, UserData userData) = 0;
};

extern "C" AIService* createAIService();

class AIStreamedInferenceListener {
 public:
  AIStreamedInferenceListener() = default;
  virtual ~AIStreamedInferenceListener() = default;
  using InferenceInProgressCallback = void (*)(UserData);
  virtual void InferenceInProgress(const std::string& data, InferenceInProgressCallback closure, UserData userData) = 0;
};

extern "C" AIStreamedInferenceListener* createAIStreamedInferenceListener();


}  // namespace arc::interop
