// arc/services/ai/public/mojom/ai_service.mojom-c_api.h is auto generated by mojom_bindings_generator.py, do not edit



#pragma once

#include <stdbool.h>
#include <stdint.h>

#ifdef __cplusplus
namespace mojoc {
#endif // __cplusplus


typedef enum {
  AIServiceTypeEmbedding = 0,
  AIServiceTypeInference = 1,
  AIServiceTypeUndefined = 2,
} AIServiceType;

typedef enum {
  AIServiceErrorIllegalState = 0,
  AIServiceErrorInvalidParameter = 1,
  AIServiceErrorNotImplemented = 2,
  AIServiceErrorNotInitialized = 3,
  AIServiceErrorAlreadyInitialized = 4,
  AIServiceErrorInvalidLibraryPath = 5,
  AIServiceErrorLibraryNotFound = 6,
  AIServiceErrorLibraryMissingRequiredSymbols = 7,
  AIServiceErrorCannotDownloadModel = 8,
  AIServiceErrorOtherError = 9,
  AIServiceErrorUndefined = 10,
} AIServiceError;

typedef enum {
  AIEmbeddingSupportedModelGteSmall = 0,
  AIEmbeddingSupportedModelGteBase = 1,
  AIEmbeddingSupportedModelGteLarge = 2,
  AIEmbeddingSupportedModelAlibabaGteBase = 3,
  AIEmbeddingSupportedModelUndefined = 4,
} AIEmbeddingSupportedModel;

typedef enum {
  AIEmbeddingMethodOnnxRuntime = 0,
  AIEmbeddingMethodCoreML = 1,
  AIEmbeddingMethodMLX = 2,
  AIEmbeddingMethodRemote = 3,
  AIEmbeddingMethodUndefined = 4,
} AIEmbeddingMethod;

typedef enum {
  AIInferenceModelTypePhi2 = 0,
  AIInferenceModelTypePhi3_5 = 1,
  AIInferenceModelTypeMistral7B = 2,
  AIInferenceModelTypeCodeLlama13b = 3,
  AIInferenceModelTypeLlama_3_2 = 4,
  AIInferenceModelTypeGemma2b = 5,
  AIInferenceModelTypeQwen205b = 6,
  AIInferenceModelTypeOpenelm270m = 7,
  AIInferenceModelTypeUndefined = 8,
} AIInferenceModelType;

typedef struct {
  uint16_t id;
  uint64_t pointer;
} UserData;

typedef struct {
  const char* string;
  unsigned int length;
} String;

typedef struct {
  const float* begin;
  unsigned int length;
} FloatArray;

typedef struct {
  AIEmbeddingMethod method;
  AIEmbeddingSupportedModel model;
} AIEmbeddingConfiguration;

typedef struct {
  AIServiceType type;
  String displayName;
  String libraryPath;
  String libraryVersion;
  int8_t maxRetries;
  double timeoutSeconds;
} AIServiceConfiguration;

typedef struct {
  int32_t maxTokens;
  int16_t streamAfterEveryNTokens;
  AIInferenceModelType modelType;
} AIStreamedInferenceConfiguration;

typedef struct {
  FloatArray* embeddings;
  unsigned int embeddingsLength;
} Embeddings;


typedef struct {
  enum AIErrorOrServiceTypeEnum {
    AIErrorOrServiceTypeEnumService_type,
    AIErrorOrServiceTypeEnumError,
  } type;
  union AIErrorOrServiceTypeUnion {
    AIServiceType serviceType;
    AIServiceError error;
  } value;
} AIErrorOrServiceType;

typedef struct {
  enum AIErrorOrEmbeddingsEnum {
    AIErrorOrEmbeddingsEnumEmbeddings,
    AIErrorOrEmbeddingsEnumError,
  } type;
  union AIErrorOrEmbeddingsUnion {
    Embeddings embeddings;
    AIServiceError error;
  } value;
} AIErrorOrEmbeddings;

// Forward declare interfaces
typedef void* AIServiceHandle;
typedef void* AIStreamedInferenceListenerHandle;
typedef struct AIStreamedInferenceListener_ AIStreamedInferenceListener;

// Definition of AIService
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  AIServiceHandle AIService_Create();
#ifdef __cplusplus
}
#endif // __cplusplus

// Methods in the AIService
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*InitializeCallback)(AIServiceError, UserData);
  typedef void (*Initialize_FnPtr_t)(AIServiceHandle handle, AIServiceConfiguration* config, InitializeCallback closure, UserData user_data);
  void Initialize(AIServiceHandle handle, AIServiceConfiguration* config, InitializeCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*TypeCallback)(AIErrorOrServiceType*, UserData);
  typedef void (*Type_FnPtr_t)(AIServiceHandle handle, TypeCallback closure, UserData user_data);
  void Type(AIServiceHandle handle, TypeCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*WaitForDebuggerToAttachCallback)(UserData);
  typedef void (*WaitForDebuggerToAttach_FnPtr_t)(AIServiceHandle handle, uint16_t seconds, WaitForDebuggerToAttachCallback closure, UserData user_data);
  void WaitForDebuggerToAttach(AIServiceHandle handle, uint16_t seconds, WaitForDebuggerToAttachCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*CrashCallback)(UserData);
  typedef void (*Crash_FnPtr_t)(AIServiceHandle handle, CrashCallback closure, UserData user_data);
  void Crash(AIServiceHandle handle, CrashCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*UpdateFeatureFlagsCallback)(bool, UserData);
  typedef void (*UpdateFeatureFlags_FnPtr_t)(AIServiceHandle handle, String feature_flags_as_json, UpdateFeatureFlagsCallback closure, UserData user_data);
  void UpdateFeatureFlags(AIServiceHandle handle, String feature_flags_as_json, UpdateFeatureFlagsCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*GetEmbeddingsForCallback)(AIErrorOrEmbeddings*, UserData);
  typedef void (*GetEmbeddingsFor_FnPtr_t)(AIServiceHandle handle, String* inputs, unsigned int inputs_length, AIEmbeddingConfiguration* config, GetEmbeddingsForCallback closure, UserData user_data);
  void GetEmbeddingsFor(AIServiceHandle handle, String* inputs, unsigned int inputs_length, AIEmbeddingConfiguration* config, GetEmbeddingsForCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*LoadInferenceModelCallback)(AIServiceError, UserData);
  typedef void (*LoadInferenceModel_FnPtr_t)(AIServiceHandle handle, AIInferenceModelType model, LoadInferenceModelCallback closure, UserData user_data);
  void LoadInferenceModel(AIServiceHandle handle, AIInferenceModelType model, LoadInferenceModelCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*GetStreamedInferenceForCallback)(AIServiceError, UserData);
  typedef void (*GetStreamedInferenceFor_FnPtr_t)(AIServiceHandle handle, String prompt, AIStreamedInferenceConfiguration* config, AIStreamedInferenceListenerHandle listener, AIStreamedInferenceListener dispatch_table, GetStreamedInferenceForCallback closure, UserData user_data);
  void GetStreamedInferenceFor(AIServiceHandle handle, String prompt, AIStreamedInferenceConfiguration* config, AIStreamedInferenceListenerHandle listener, AIStreamedInferenceListener dispatch_table, GetStreamedInferenceForCallback closure, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus


// Methods in the AIStreamedInferenceListener
#ifdef __cplusplus
extern "C" {
#endif // __cplusplus
  typedef void (*InferenceInProgress_FnPtr_t)(AIStreamedInferenceListenerHandle handle, String data, UserData user_data);
#ifdef __cplusplus
}
#endif // __cplusplus

struct AIStreamedInferenceListener_ {
  InferenceInProgress_FnPtr_t inferenceInProgress;
};

typedef struct {
  enum AIServiceSymbolType {
    AIServiceSymbolTypeInitialize,
    AIServiceSymbolTypeType,
    AIServiceSymbolTypeWaitForDebuggerToAttach,
    AIServiceSymbolTypeCrash,
    AIServiceSymbolTypeUpdateFeatureFlags,
    AIServiceSymbolTypeGetEmbeddingsFor,
    AIServiceSymbolTypeLoadInferenceModel,
    AIServiceSymbolTypeGetStreamedInferenceFor,
  } type;

  union AIServiceSymbolValue {
    Initialize_FnPtr_t Initialize;
    Type_FnPtr_t Type;
    WaitForDebuggerToAttach_FnPtr_t WaitForDebuggerToAttach;
    Crash_FnPtr_t Crash;
    UpdateFeatureFlags_FnPtr_t UpdateFeatureFlags;
    GetEmbeddingsFor_FnPtr_t GetEmbeddingsFor;
    LoadInferenceModel_FnPtr_t LoadInferenceModel;
    GetStreamedInferenceFor_FnPtr_t GetStreamedInferenceFor;
  } value;
} AIServiceSymbol;


typedef struct {
  enum AIStreamedInferenceListenerSymbolType {
    AIStreamedInferenceListenerSymbolTypeInferenceInProgress,
  } type;

  union AIStreamedInferenceListenerSymbolValue {
    InferenceInProgress_FnPtr_t InferenceInProgress;
  } value;
} AIStreamedInferenceListenerSymbol;



const char kSymbolAIService_Create[] = "AIService_Create";
const char kSymbolAIService_Initialize[] = "AIService_Initialize";
const char kSymbolAIService_Type[] = "AIService_Type";
const char kSymbolAIService_WaitForDebuggerToAttach[] = "AIService_WaitForDebuggerToAttach";
const char kSymbolAIService_Crash[] = "AIService_Crash";
const char kSymbolAIService_UpdateFeatureFlags[] = "AIService_UpdateFeatureFlags";
const char kSymbolAIService_GetEmbeddingsFor[] = "AIService_GetEmbeddingsFor";
const char kSymbolAIService_LoadInferenceModel[] = "AIService_LoadInferenceModel";
const char kSymbolAIService_GetStreamedInferenceFor[] = "AIService_GetStreamedInferenceFor";

static const char* Symbols[] = {
  kSymbolAIService_Create,
  kSymbolAIService_Initialize,
  kSymbolAIService_Type,
  kSymbolAIService_WaitForDebuggerToAttach,
  kSymbolAIService_Crash,
  kSymbolAIService_UpdateFeatureFlags,
  kSymbolAIService_GetEmbeddingsFor,
  kSymbolAIService_LoadInferenceModel,
  kSymbolAIService_GetStreamedInferenceFor
};
#ifdef __cplusplus
}  // namespace mojoc
#endif // __cplusplus
